{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTSQRq9rP37B"
      },
      "source": [
        "# Rock, Paper, and Scissors\n",
        "\n",
        "## i'm running it in Google Collab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bfYPDUWWP37O"
      },
      "outputs": [],
      "source": [
        "from os import getcwd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ll98_pP37U"
      },
      "source": [
        "## Make one hot encoding for the labels. the labels have 3 classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7XityKUP37f",
        "outputId": "c47f8d32-917b-4ee3-d2ce-fb0666e5be87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]], shape=(5, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def OneHotEncoding(feature, label):\n",
        "    one_hot = tf.one_hot(label, 3)\n",
        "    return feature, one_hot\n",
        "\n",
        "\n",
        "# Test the function\n",
        "_,one_hot = OneHotEncoding([\"a\", \"b\", \"c\", \"a\", \"b\"], [1, 2, 3, 1, 2])\n",
        "print(one_hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L5DhxS7P37g"
      },
      "source": [
        "## Load The Dataset and Explore it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9GxYqscP37h",
        "outputId": "73a580e9-33c5-445c-88db-95beffbd2c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of train data: 2520\n",
            "Amount of test data: 372\n",
            "(300, 300, 3)\n"
          ]
        }
      ],
      "source": [
        "filepath = f\"{getcwd()}/data\"\n",
        "\n",
        "train_data = tfds.load(\"rock_paper_scissors:3.*.*\", split=\"train\", data_dir = filepath, as_supervised=True)\n",
        "test_data = tfds.load(\"rock_paper_scissors:3.*.*\", split=\"test\", data_dir = filepath, as_supervised=True)\n",
        "\n",
        "# Knowing the amount of data\n",
        "print(f\"Amount of train data: {len(list(train_data))}\")\n",
        "print(f\"Amount of test data: {len(list(test_data))}\")\n",
        "\n",
        "# Knowing the shape of image\n",
        "_,info = tfds.load(\"rock_paper_scissors:3.*.*\", with_info=True, data_dir=filepath)\n",
        "\n",
        "# DO NOT EDIT THIS\n",
        "print(info.features['image'].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BslMiptHP37i"
      },
      "source": [
        "## Mapping dataset use one hot encode function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg3seoD6P37i",
        "outputId": "ba8f3b03-a981-4bc6-a6a7-ba57e1a6a5cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.data.ops.map_op._MapDataset'>\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data.map(OneHotEncoding)\n",
        "test_data = test_data.map(OneHotEncoding)\n",
        "\n",
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQWdAvssP37j"
      },
      "source": [
        "## Make a model CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S18K3yrPP37k",
        "outputId": "91d8a94c-b2b1-4894-fa8d-8f1749de98a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 298, 298, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 149, 149, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 147, 147, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 71, 71, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 33, 33, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               16777472  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17166659 (65.49 MB)\n",
            "Trainable params: 17166659 (65.49 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Conv2D(32,(3, 3), activation=\"relu\", input_shape=(300, 300, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(64,(3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(128,(3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Conv2D(256,(3, 3), activation=\"relu\"),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(256, activation=\"relu\"),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EO2qY56hP37l"
      },
      "source": [
        "## Evaluate model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = train_data.shuffle(100).batch(10)\n",
        "validation_batches = test_data.batch(32)"
      ],
      "metadata": {
        "id": "VJ6sTitnT0Pz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ion0yRvKP37m",
        "outputId": "c1143b6b-ee91-4cd9-ce45-c53472e24c97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "  5/252 [..............................] - ETA: 8s - loss: 25.6183 - accuracy: 0.3600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0122s vs `on_train_batch_end` time: 0.0169s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "252/252 [==============================] - 16s 39ms/step - loss: 4.0982 - accuracy: 0.5623 - val_loss: 0.6843 - val_accuracy: 0.6875\n",
            "Epoch 2/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.5798 - accuracy: 0.7393 - val_loss: 0.6544 - val_accuracy: 0.7812\n",
            "Epoch 3/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.4030 - accuracy: 0.8206 - val_loss: 0.4978 - val_accuracy: 0.8750\n",
            "Epoch 4/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.3027 - accuracy: 0.8726 - val_loss: 0.4639 - val_accuracy: 0.8125\n",
            "Epoch 5/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.2058 - accuracy: 0.9202 - val_loss: 0.3092 - val_accuracy: 0.8750\n",
            "Epoch 6/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.1651 - accuracy: 0.9361 - val_loss: 0.4180 - val_accuracy: 0.8438\n",
            "Epoch 7/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.1115 - accuracy: 0.9591 - val_loss: 0.4514 - val_accuracy: 0.8438\n",
            "Epoch 8/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.1008 - accuracy: 0.9619 - val_loss: 0.3582 - val_accuracy: 0.8750\n",
            "Epoch 9/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.1053 - accuracy: 0.9611 - val_loss: 0.3605 - val_accuracy: 0.9375\n",
            "Epoch 10/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0685 - accuracy: 0.9758 - val_loss: 0.3572 - val_accuracy: 0.8750\n",
            "Epoch 11/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0778 - accuracy: 0.9722 - val_loss: 0.3348 - val_accuracy: 0.9375\n",
            "Epoch 12/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0606 - accuracy: 0.9738 - val_loss: 0.4626 - val_accuracy: 0.8438\n",
            "Epoch 13/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.4597 - val_accuracy: 0.8750\n",
            "Epoch 14/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.5213 - val_accuracy: 0.8750\n",
            "Epoch 15/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0330 - accuracy: 0.9893 - val_loss: 0.4104 - val_accuracy: 0.9375\n",
            "Epoch 16/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0484 - accuracy: 0.9849 - val_loss: 0.4553 - val_accuracy: 0.8750\n",
            "Epoch 17/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0602 - accuracy: 0.9774 - val_loss: 0.7165 - val_accuracy: 0.8125\n",
            "Epoch 18/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0263 - accuracy: 0.9925 - val_loss: 0.4203 - val_accuracy: 0.9375\n",
            "Epoch 19/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.3331 - val_accuracy: 0.9375\n",
            "Epoch 20/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0312 - accuracy: 0.9873 - val_loss: 0.4075 - val_accuracy: 0.9062\n",
            "Epoch 21/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0354 - accuracy: 0.9849 - val_loss: 0.5980 - val_accuracy: 0.8438\n",
            "Epoch 22/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0276 - accuracy: 0.9909 - val_loss: 0.5708 - val_accuracy: 0.9062\n",
            "Epoch 23/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0186 - accuracy: 0.9925 - val_loss: 0.5328 - val_accuracy: 0.9062\n",
            "Epoch 24/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 0.6430 - val_accuracy: 0.8438\n",
            "Epoch 25/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.5195 - val_accuracy: 0.8750\n",
            "Epoch 26/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0192 - accuracy: 0.9956 - val_loss: 0.6214 - val_accuracy: 0.9062\n",
            "Epoch 27/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0101 - accuracy: 0.9964 - val_loss: 0.6869 - val_accuracy: 0.8750\n",
            "Epoch 28/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0200 - accuracy: 0.9921 - val_loss: 0.6394 - val_accuracy: 0.8438\n",
            "Epoch 29/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.7785 - val_accuracy: 0.9062\n",
            "Epoch 30/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0145 - accuracy: 0.9960 - val_loss: 0.5109 - val_accuracy: 0.9375\n",
            "Epoch 31/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0151 - accuracy: 0.9948 - val_loss: 0.5869 - val_accuracy: 0.9062\n",
            "Epoch 32/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 0.5250 - val_accuracy: 0.9375\n",
            "Epoch 33/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.5907 - val_accuracy: 0.9375\n",
            "Epoch 34/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 0.8506 - val_accuracy: 0.8750\n",
            "Epoch 35/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.5629 - val_accuracy: 0.9375\n",
            "Epoch 36/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.5951 - val_accuracy: 0.9375\n",
            "Epoch 37/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.6946 - val_accuracy: 0.9375\n",
            "Epoch 38/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0139 - accuracy: 0.9944 - val_loss: 0.6886 - val_accuracy: 0.9375\n",
            "Epoch 39/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.5442 - val_accuracy: 0.9062\n",
            "Epoch 40/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0064 - accuracy: 0.9980 - val_loss: 0.6259 - val_accuracy: 0.8750\n",
            "Epoch 41/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.6242 - val_accuracy: 0.9062\n",
            "Epoch 42/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0199 - accuracy: 0.9964 - val_loss: 0.5205 - val_accuracy: 0.9062\n",
            "Epoch 43/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0030 - accuracy: 0.9984 - val_loss: 0.6117 - val_accuracy: 0.9062\n",
            "Epoch 44/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.6905 - val_accuracy: 0.9062\n",
            "Epoch 45/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.7860 - val_accuracy: 0.9062\n",
            "Epoch 46/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.7075 - val_accuracy: 0.9375\n",
            "Epoch 47/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.9287 - val_accuracy: 0.9062\n",
            "Epoch 48/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 0.9080 - val_accuracy: 0.9062\n",
            "Epoch 49/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 0.7926 - val_accuracy: 0.8750\n",
            "Epoch 50/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 9.3798e-04 - accuracy: 1.0000 - val_loss: 0.7641 - val_accuracy: 0.9062\n",
            "Epoch 51/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 1.7483 - val_accuracy: 0.8438\n",
            "Epoch 52/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0070 - accuracy: 0.9972 - val_loss: 0.6789 - val_accuracy: 0.8125\n",
            "Epoch 53/1000\n",
            "252/252 [==============================] - 9s 34ms/step - loss: 0.0097 - accuracy: 0.9960 - val_loss: 0.7304 - val_accuracy: 0.9062\n",
            "Epoch 54/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0105 - accuracy: 0.9984 - val_loss: 0.8928 - val_accuracy: 0.9062\n",
            "Epoch 55/1000\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.7667 - val_accuracy: 0.9062\n",
            "Epoch 56/1000\n",
            "251/252 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9976\n",
            "Reached 97% accuracy so cancelling training!\n",
            "252/252 [==============================] - 9s 35ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.6882 - val_accuracy: 0.9688\n",
            "Final Training Accuracy:- 0.9976190328598022\n",
            "Final Validation Accuracy:- 0.96875\n"
          ]
        }
      ],
      "source": [
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get(\"accuracy\") > 0.96 and logs.get(\"val_accuracy\") > 0.96:\n",
        "            print(\"\\nReached 97% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "# Buat instance dari callback\n",
        "my_callback = MyCallback()\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_batches, epochs=1000, validation_data=validation_batches,validation_steps=1, callbacks=[my_callback]\n",
        ")\n",
        "\n",
        "print(\"Final Training Accuracy:-\", history.history[\"accuracy\"][-1])\n",
        "print(\"Final Validation Accuracy:-\", history.history[\"val_accuracy\"][-1])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}